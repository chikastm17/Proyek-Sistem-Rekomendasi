{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de104cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\OneDrive\\Documents\\Semester 5\\Certan\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"All libraries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ae3185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0002005018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>074322678X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0887841740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1552041778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1567407781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id     item_id\n",
       "0        8  0002005018\n",
       "1        8  074322678X\n",
       "2        8  0887841740\n",
       "3        8  1552041778\n",
       "4        8  1567407781"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\User\\OneDrive\\Documents\\DEL DEL DEL\\Semester 7\\SisRek\\data-books\\train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d4c31c",
   "metadata": {},
   "source": [
    "### Step 3: Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5109148e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users: 13876, items: 123069\n"
     ]
    }
   ],
   "source": [
    "df['rating'] = 1  # implicit feedback, semua interaksi dianggap positif (rating=1)\n",
    "\n",
    "user_ids = df['user_id'].unique()\n",
    "item_ids = df['item_id'].unique()\n",
    "\n",
    "user_map = {u:i for i,u in enumerate(user_ids)}\n",
    "item_map = {i:j for j,i in enumerate(item_ids)}\n",
    "inv_item_map = {v:k for k,v in item_map.items()}\n",
    "\n",
    "df['user_idx'] = df['user_id'].map(user_map)\n",
    "df['item_idx'] = df['item_id'].map(item_map)\n",
    "\n",
    "n_users = len(user_map)\n",
    "n_items = len(item_map)\n",
    "print(f\"Total users: {n_users}, items: {n_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23222bfe",
   "metadata": {},
   "source": [
    "### Step 4: Split Data (Train-Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b5e5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255888 train interactions, 13876 test interactions\n"
     ]
    }
   ],
   "source": [
    "import numpy.random as random\n",
    "\n",
    "train_rows, test_rows = [], []\n",
    "rng = random.default_rng(42)\n",
    "\n",
    "for u, group in df.groupby('user_idx'):\n",
    "    items = group['item_idx'].tolist()\n",
    "    if len(items) > 1:\n",
    "        test_item = rng.choice(items)\n",
    "        for it in items:\n",
    "            if it == test_item:\n",
    "                test_rows.append((u,it,1))\n",
    "            else:\n",
    "                train_rows.append((u,it,1))\n",
    "    else:\n",
    "        for it in items:\n",
    "            train_rows.append((u,it,1))\n",
    "\n",
    "train_df = pd.DataFrame(train_rows, columns=['user_idx','item_idx','rating'])\n",
    "test_df = pd.DataFrame(test_rows, columns=['user_idx','item_idx','rating'])\n",
    "\n",
    "print(len(train_df), \"train interactions,\", len(test_df), \"test interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3fe783",
   "metadata": {},
   "source": [
    "### Step 5: Bangun Matriks Sparse (untuk Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2c081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = sp.coo_matrix((train_df['rating'].values,\n",
    "                   (train_df['item_idx'].values, train_df['user_idx'].values)),\n",
    "                  shape=(n_items, n_users)).tocsr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fda5df",
   "metadata": {},
   "source": [
    "### Step 6: Baseline Model 1 — Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b646b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pop = np.array(R.sum(axis=1)).ravel()\n",
    "popular_items = np.argsort(-item_pop)\n",
    "\n",
    "def recommend_popularity(user_idx, k=10):\n",
    "    seen = set(train_df[train_df['user_idx']==user_idx]['item_idx'])\n",
    "    recs = [i for i in popular_items if i not in seen][:k]\n",
    "    return recs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6181d97",
   "metadata": {},
   "source": [
    "### Step 7: Baseline Model 2 — Item-based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4177258",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_SIM_ITEMS = 2000\n",
    "top_items = popular_items[:TOP_SIM_ITEMS]\n",
    "\n",
    "M = R[top_items,:].toarray()\n",
    "item_sim = cosine_similarity(M)\n",
    "pos_of_item_in_top = {item:i for i,item in enumerate(top_items)}\n",
    "\n",
    "def recommend_itemcf(user_idx, k=10):\n",
    "    user_items = train_df[train_df['user_idx']==user_idx]['item_idx'].tolist()\n",
    "    scores = np.zeros(len(top_items))\n",
    "    for it in user_items:\n",
    "        if it in pos_of_item_in_top:\n",
    "            scores += item_sim[pos_of_item_in_top[it]]\n",
    "    recs = []\n",
    "    for idx in np.argsort(-scores):\n",
    "        item = top_items[idx]\n",
    "        if item not in user_items:\n",
    "            recs.append(item)\n",
    "            if len(recs) == k: break\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64df4e7",
   "metadata": {},
   "source": [
    "### Step 8: Evaluasi MAP@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "982e6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "    score, num_hits = 0.0, 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actuals, predicteds, k=10):\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actuals, predicteds)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4a250a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10 Popularity: 0.00520483008231639\n",
      "MAP@10 Item-CF: 0.015433093339190195\n"
     ]
    }
   ],
   "source": [
    "test_users = test_df['user_idx'].tolist()\n",
    "actuals = [[it] for it in test_df['item_idx'].tolist()]\n",
    "\n",
    "pred_pop = [recommend_popularity(u,10) for u in test_users]\n",
    "pred_item = [recommend_itemcf(u,10) for u in test_users]\n",
    "\n",
    "print(\"MAP@10 Popularity:\", mapk(actuals, pred_pop))\n",
    "print(\"MAP@10 Item-CF:\", mapk(actuals, pred_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7f825bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting implicit==0.7.2\n",
      "  Obtaining dependency information for implicit==0.7.2 from https://files.pythonhosted.org/packages/7c/25/48964efed207b60b2d5b2855161638e4f368f5db332b57f62b6cd16fb591/implicit-0.7.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading implicit-0.7.2-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\user\\onedrive\\documents\\semester 5\\certan\\lib\\site-packages (from implicit==0.7.2) (1.24.4)\n",
      "Requirement already satisfied: scipy>=0.16 in c:\\users\\user\\onedrive\\documents\\semester 5\\certan\\lib\\site-packages (from implicit==0.7.2) (1.9.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\onedrive\\documents\\semester 5\\certan\\lib\\site-packages (from implicit==0.7.2) (4.65.0)\n",
      "Requirement already satisfied: threadpoolctl in c:\\users\\user\\onedrive\\documents\\semester 5\\certan\\lib\\site-packages (from implicit==0.7.2) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\onedrive\\documents\\semester 5\\certan\\lib\\site-packages (from tqdm>=4.27->implicit==0.7.2) (0.4.6)\n",
      "Downloading implicit-0.7.2-cp311-cp311-win_amd64.whl (750 kB)\n",
      "   ---------------------------------------- 0.0/750.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/750.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/750.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/750.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/750.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/750.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/750.8 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 41.0/750.8 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 41.0/750.8 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 41.0/750.8 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 81.9/750.8 kB 459.5 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 81.9/750.8 kB 459.5 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 81.9/750.8 kB 459.5 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 81.9/750.8 kB 459.5 kB/s eta 0:00:02\n",
      "   ------ ------------------------------- 122.9/750.8 kB 359.9 kB/s eta 0:00:02\n",
      "   ------ ------------------------------- 122.9/750.8 kB 359.9 kB/s eta 0:00:02\n",
      "   ------- ------------------------------ 143.4/750.8 kB 327.9 kB/s eta 0:00:02\n",
      "   -------- ----------------------------- 163.8/750.8 kB 327.5 kB/s eta 0:00:02\n",
      "   -------- ----------------------------- 174.1/750.8 kB 317.5 kB/s eta 0:00:02\n",
      "   -------- ----------------------------- 174.1/750.8 kB 317.5 kB/s eta 0:00:02\n",
      "   ---------- --------------------------- 204.8/750.8 kB 319.5 kB/s eta 0:00:02\n",
      "   ---------- --------------------------- 204.8/750.8 kB 319.5 kB/s eta 0:00:02\n",
      "   ---------- --------------------------- 204.8/750.8 kB 319.5 kB/s eta 0:00:02\n",
      "   ---------- --------------------------- 204.8/750.8 kB 319.5 kB/s eta 0:00:02\n",
      "   ------------ ------------------------- 245.8/750.8 kB 295.5 kB/s eta 0:00:02\n",
      "   ------------ ------------------------- 256.0/750.8 kB 296.8 kB/s eta 0:00:02\n",
      "   ------------- ------------------------ 276.5/750.8 kB 304.3 kB/s eta 0:00:02\n",
      "   ------------- ------------------------ 276.5/750.8 kB 304.3 kB/s eta 0:00:02\n",
      "   ---------------- --------------------- 327.7/750.8 kB 317.4 kB/s eta 0:00:02\n",
      "   ----------------- -------------------- 337.9/750.8 kB 313.0 kB/s eta 0:00:02\n",
      "   ----------------- -------------------- 337.9/750.8 kB 313.0 kB/s eta 0:00:02\n",
      "   ----------------- -------------------- 337.9/750.8 kB 313.0 kB/s eta 0:00:02\n",
      "   ------------------ ------------------- 368.6/750.8 kB 301.7 kB/s eta 0:00:02\n",
      "   ------------------- ------------------ 389.1/750.8 kB 307.0 kB/s eta 0:00:02\n",
      "   ------------------- ------------------ 389.1/750.8 kB 307.0 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 419.8/750.8 kB 312.0 kB/s eta 0:00:02\n",
      "   ---------------------- --------------- 440.3/750.8 kB 312.8 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 450.6/750.8 kB 316.5 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 491.5/750.8 kB 331.2 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 501.8/750.8 kB 324.2 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 501.8/750.8 kB 324.2 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 501.8/750.8 kB 324.2 kB/s eta 0:00:01\n",
      "   ------------------------- ------------ 501.8/750.8 kB 324.2 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 522.2/750.8 kB 309.2 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 532.5/750.8 kB 301.2 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 553.0/750.8 kB 307.3 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 583.7/750.8 kB 311.0 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 583.7/750.8 kB 311.0 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 614.4/750.8 kB 314.3 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 614.4/750.8 kB 314.3 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 614.4/750.8 kB 314.3 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 634.9/750.8 kB 300.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 655.4/750.8 kB 303.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 655.4/750.8 kB 303.6 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 686.1/750.8 kB 304.6 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 686.1/750.8 kB 304.6 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 686.1/750.8 kB 304.6 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 696.3/750.8 kB 290.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 696.3/750.8 kB 290.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 696.3/750.8 kB 290.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 696.3/750.8 kB 290.8 kB/s eta 0:00:01\n",
      "   -------------------------------------  737.3/750.8 kB 290.8 kB/s eta 0:00:01\n",
      "   -------------------------------------  737.3/750.8 kB 290.8 kB/s eta 0:00:01\n",
      "   -------------------------------------  737.3/750.8 kB 290.8 kB/s eta 0:00:01\n",
      "   -------------------------------------  737.3/750.8 kB 290.8 kB/s eta 0:00:01\n",
      "   -------------------------------------  737.3/750.8 kB 290.8 kB/s eta 0:00:01\n",
      "   -------------------------------------  737.3/750.8 kB 290.8 kB/s eta 0:00:01\n",
      "   -------------------------------------  737.3/750.8 kB 290.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- 750.8/750.8 kB 259.0 kB/s eta 0:00:00\n",
      "Installing collected packages: implicit\n",
      "Successfully installed implicit-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install implicit==0.7.2 --prefer-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52759890",
   "metadata": {},
   "source": [
    "### Step 9: Model-Based — Implicit ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aeeddf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id     item_id\n",
      "0        8  0002005018\n",
      "1        8  074322678X\n",
      "2        8  0887841740\n",
      "3        8  1552041778\n",
      "4        8  1567407781\n",
      "Matrix shape: (13876, 123069)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Baca dataset\n",
    "train_df = pd.read_csv(r\"C:\\Users\\User\\OneDrive\\Documents\\DEL DEL DEL\\Semester 7\\SisRek\\data-books\\train.csv\")  # ganti path sesuai file kamu\n",
    "\n",
    "# Lihat beberapa data\n",
    "print(train_df.head())\n",
    "\n",
    "# Tambahkan kolom interaksi (semua = 1)\n",
    "train_df['interaction'] = 1\n",
    "\n",
    "# Buat mapping user dan item jadi index numerik\n",
    "user_mapping = {u: i for i, u in enumerate(train_df['user_id'].unique())}\n",
    "item_mapping = {i: j for j, i in enumerate(train_df['item_id'].unique())}\n",
    "\n",
    "train_df['user_idx'] = train_df['user_id'].map(user_mapping)\n",
    "train_df['item_idx'] = train_df['item_id'].map(item_mapping)\n",
    "\n",
    "# Buat user-item matrix (CSR)\n",
    "R = csr_matrix(\n",
    "    (train_df['interaction'].astype(float),\n",
    "     (train_df['user_idx'], train_df['item_idx']))\n",
    ")\n",
    "\n",
    "print(\"Matrix shape:\", R.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36259607",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'R' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 1. pastikan matriks interaksi sudah dibuat\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m R_csr \u001b[38;5;241m=\u001b[39m csr_matrix(R)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 2. ambil daftar user yang ada di data test\u001b[39;00m\n\u001b[0;32m      8\u001b[0m test_users \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'R' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# 1. pastikan matriks interaksi sudah dibuat\n",
    "R_csr = csr_matrix(R)\n",
    "\n",
    "# 2. ambil daftar user yang ada di data test\n",
    "test_users = test_df['user_idx'].unique()\n",
    "\n",
    "# 3. ambil ground truth (item yang sebenarnya di-like user di test set)\n",
    "actuals = (\n",
    "    test_df.groupby('user_idx')['item_idx']\n",
    "    .apply(list)\n",
    "    .reindex(test_users)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# 4. generate rekomendasi\n",
    "pred_als = []\n",
    "for u in tqdm(test_users):\n",
    "    recs, _ = model.recommend(\n",
    "        userid=u,\n",
    "        user_items=R_csr,\n",
    "        N=10,\n",
    "        filter_already_liked_items=True\n",
    "    )\n",
    "    pred_als.append(recs)\n",
    "\n",
    "# 5. hitung MAP@10\n",
    "print(\"MAP@10 ALS:\", mapk(actuals, pred_als))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f861455a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(user_mapping)\n\u001b[0;32m      5\u001b[0m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(item_mapping)\n\u001b[1;32m----> 6\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(user_mapping)\n\u001b[0;32m      7\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(item_mapping)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "user_mapping = {u: i for i, u in enumerate(train_df['user_id'].unique())}\n",
    "item_mapping = {i: j for j, i in enumerate(train_df['item_id'].unique())}\n",
    "\n",
    "train_df['user_idx'] = train_df['user_id'].map(user_mapping)\n",
    "train_df['item_idx'] = train_df['item_id'].map(item_mapping)\n",
    "test_df['user_idx'] = test_df['user_id'].map(user_mapping)\n",
    "test_df['item_idx'] = test_df['item_id'].map(item_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a756f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
